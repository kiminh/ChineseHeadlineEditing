{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchfly.modules.transformers import CachedBertDecoderLM, ChineseBERTBaseConfig\n",
    "from torchfly.text.tokenizers import BertTokenizer\n",
    "from torchfly.utils import get_pretrained_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading bert-base-chinese-vocab.json\n",
      "100%|██████████| 109540/109540 [00:00<00:00, 455666.13B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cached Downloading: /home/wuqy1203/.cache/torchfly/models/chinese-gpt-bert-small.pth\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1agi64d06PlBe6XUz2IMkgl8ZKjw6H7nS\n",
      "To: /home/wuqy1203/.cache/gdown/tmp5brfz297/dl\n",
      "407MB [00:17, 22.6MB/s] \n"
     ]
    }
   ],
   "source": [
    "model_states = get_pretrained_states(\"chinese-gpt-bert-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CachedBertDecoderLM(ChineseBERTBaseConfig)\n",
    "model.load_state_dict(model_states, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_logits(logits, k):\n",
    "    \"\"\"Mask logits so that only top-k logits remain\n",
    "    \"\"\"\n",
    "    values, _ = torch.topk(logits, k)\n",
    "    min_values = values[:, -1].unsqueeze(1).repeat(1, logits.shape[-1])\n",
    "    return torch.where(logits < min_values, torch.ones_like(logits, dtype=logits.dtype) * -1e10, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = tokenizer.encode(\"阿里巴巴集团宣布收购雅虎\")\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 50\n",
    "temperature = 0.8\n",
    "length = 0\n",
    "\n",
    "start_predictions = torch.LongTensor([[101] + prompt]* batch_size).to(device)\n",
    "mask = torch.ones(batch_size, start_predictions.shape[1]).to(device)\n",
    "\n",
    "past = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    # cache saves in past\n",
    "    logits, past = model(start_predictions, mask, past=None, past_length=0)\n",
    "    logits = logits[:, -1, :] / temperature\n",
    "    logits = top_k_logits(logits, k=top_k)\n",
    "\n",
    "    sentence = []\n",
    "\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    prob, prev_pred = torch.topk(probs, k=1, dim=-1)\n",
    "    sentence.append(prev_pred)\n",
    "    length += 1\n",
    "\n",
    "    # decoding loop\n",
    "    for i in range(500):\n",
    "        mask = F.pad(mask, (0, 1), \"constant\", 1.0)\n",
    "        logits, past = model(prev_pred, mask, past=past, past_length=length)\n",
    "        logits = logits.squeeze(1) / temperature\n",
    "        logits = top_k_logits(logits, k=top_k)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        prev_pred = torch.multinomial(probs, num_samples=1)\n",
    "        sentence.append(prev_pred)\n",
    "        length += 1\n",
    "\n",
    "    sentence = torch.cat(sentence, dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'的创认为，这次交时间炸机是因为他本身的产品经验，3/4的股权是因为他提供了多个合作伙伴，当时，雅虎联合创始人员员工在阿里大战中的表现就不容易，这在全球上是不多的了，也从不能令人信赖。在这样一个巨大的市场中，大型公司，雅虎也有自己独特的优势，在网络上不可避免的会员人数占比的不利，这样的人员配备和使用方便是他们在网上最大的优势。公司创始人们还是不忘经营的人，阿里旗下的几家互联网公司也是不会放弃任何一个公司的。1．利用搜索引擎的特点：这个引擎在搜索引擎中的作用不仅仅在搜索结果中，还会为了增加网站内容数量，使用这个引擎时，我们将会得到一些相关的建立工具，这些网站内容在网站文章中一目了然，而且在网站外包给中国用的时候，就是因为我们能够够了。2．雅虎搜索引擎的分类是一项很实用的工具，他的含义与前几代的\"原型\"和\"合作\"有显著区别。3．雅虎的网络推广应用的方法简单、便利，不仅仅是以搜索引擎的名义进行的。4．使用雅虎\"出生的第一天子\"属于什么类型？---雅虎\"出生的第一天子\"就是第三个时期5．什么是\"出生的第一天子\"，这是两个字母的组合，而且是不是意在改变?如果是不能6．雅虎是个人，是一种时间，或者是一'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sentence[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
