{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchfly\n",
    "# need to be called before import torch\n",
    "torchfly.set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import logging\n",
    "from apex import amp\n",
    "from apex.optimizers import FusedAdam\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torchfly.utils import gdrive_download\n",
    "from torchfly.training.checkpointer import SimpleCheckpointer\n",
    "from torchfly.modules.transformers import CachedBertEncoder, CachedBertDecoderLM, ChineseBERTBaseConfig\n",
    "from torchfly.training.optimization import AdamW, WarmupLinearSchedule\n",
    "from torchfly.modules.losses import SequenceFocalLoss, SequenceCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchfly.init_logging()\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set alpha and beta value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha\n",
    "a = 0.5\n",
    "\n",
    "# beta\n",
    "b = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIAHeadlineDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.dataset = data\n",
    "        self.CLS = [101]\n",
    "        self.SEP = [102]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        summary, origin_title, target_title = self.dataset[idx]\n",
    "        origin_title = tokenizer.convert_tokens_to_ids(origin_title)\n",
    "        target_title = tokenizer.convert_tokens_to_ids(target_title)\n",
    "\n",
    "        # source and token type\n",
    "        if np.random.rand() < 0.9:\n",
    "            max_len = 509 - len(origin_title)\n",
    "            if len(summary) > max_len:\n",
    "                summary = summary[:max_len]\n",
    "            summary = tokenizer.convert_tokens_to_ids(summary)\n",
    "            source = self.CLS + summary + self.SEP + origin_title + self.SEP\n",
    "            source_type_ids = [0] * (len(summary) + 2) + [1] * (len(origin_title) + 1)\n",
    "        else:\n",
    "            max_len = 510\n",
    "            if len(summary) > max_len:\n",
    "                summary = summary[:max_len]\n",
    "            summary = tokenizer.convert_tokens_to_ids(summary)\n",
    "            source = self.CLS + summary + self.SEP\n",
    "            source_type_ids = [0] * len(source)\n",
    "\n",
    "        target = self.CLS + target_title + self.SEP\n",
    "\n",
    "        # turn into tensors\n",
    "        source = torch.LongTensor(source)\n",
    "        source_mask = torch.ones(source.shape[0])\n",
    "        target = torch.LongTensor(target)\n",
    "        target_mask = torch.ones(target.shape[0])\n",
    "        source_type_ids = torch.LongTensor(source_type_ids)\n",
    "\n",
    "        return source, source_mask, source_type_ids, target, target_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def mod_collate(batch):\n",
    "        source, source_mask, source_type_ids, target, target_mask = zip(*batch)\n",
    "\n",
    "        # pad sequence\n",
    "        source = pad_sequence(source, batch_first=True)\n",
    "        source_mask = pad_sequence(source_mask, batch_first=True).bool()\n",
    "        source_type_ids = pad_sequence(source_type_ids, batch_first=True)\n",
    "\n",
    "        target = pad_sequence(target, batch_first=True)\n",
    "        target_mask = pad_sequence(target_mask, batch_first=True).bool()\n",
    "\n",
    "        return source, source_mask, source_type_ids, target, target_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_iter(batch, fp16=False):\n",
    "    batch = [item.to(device) for item in batch]\n",
    "    source_ids, source_mask, source_type_ids, target_ids, target_mask = batch\n",
    "\n",
    "    _, past = encoder(source_ids,\n",
    "                      token_type_ids=source_type_ids,\n",
    "                      mask=source_mask)\n",
    "\n",
    "    mask = torch.cat([source_mask, target_mask], dim=1)\n",
    "    logits, _ = decoder(target_ids, mask=mask, past=past)\n",
    "\n",
    "    out = logits[:, :-1].contiguous()\n",
    "    target = target_ids[:, 1:].contiguous()\n",
    "    target_mask = target_mask[:, 1:].contiguous()\n",
    "\n",
    "    loss = criterion(out, target, target_mask, label_smoothing=0.02, reduce=True)\n",
    "    loss /= num_gradients_accumulation\n",
    "\n",
    "    # fp16 support\n",
    "    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        scaled_loss.backward()\n",
    "    \n",
    "    # gradient clipping\n",
    "    torch.nn.utils.clip_grad_norm_(list(encoder.parameters()) + list(decoder.parameters()), 1.0)\n",
    "\n",
    "    record_loss = loss.item() * num_gradients_accumulation\n",
    "    perplexity = np.exp(record_loss)\n",
    "\n",
    "    return record_loss, perplexity\n",
    "\n",
    "\n",
    "def validate(dataloader):\n",
    "    with torch.no_grad():\n",
    "        pb = tqdm.tqdm(dataloader)\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        total_ppl = []\n",
    "\n",
    "        for batch in pb:\n",
    "            batch = [item.to(device) for item in batch]\n",
    "\n",
    "            source_ids, source_mask, source_type_ids, target_ids, target_mask = batch\n",
    "\n",
    "            _, past = encoder(source_ids,\n",
    "                              token_type_ids=source_type_ids,\n",
    "                              mask=source_mask)\n",
    "\n",
    "            mask = torch.cat([source_mask, target_mask], dim=1)\n",
    "            logits, _ = decoder(target_ids, mask=mask, past=past)\n",
    "\n",
    "            out = logits[:, :-1].contiguous()\n",
    "            target = target_ids[:, 1:].contiguous()\n",
    "            target_mask = target_mask[:, 1:].contiguous()\n",
    "\n",
    "            loss = eval_criterion(out, target, target_mask, label_smoothing=-1, reduce=\"sentence\")\n",
    "\n",
    "            ppl = torch.exp(loss)\n",
    "            total_ppl.extend(ppl.tolist())\n",
    "\n",
    "    return np.mean(total_ppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load(\"../data/PHED/train_tokenized.pkl\")\n",
    "val_data = torch.load(\"../data/PHED/val_tokenized.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SIAHeadlineDataset(train_data)\n",
    "val_dataset = SIAHeadlineDataset(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size, \n",
    "    collate_fn=SIAHeadlineDataset.mod_collate\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset, \n",
    "                            shuffle=False, \n",
    "                            batch_size=batch_size, \n",
    "                            collate_fn=SIAHeadlineDataset.mod_collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'torchfly.modules.transformers.model_configs',\n",
       "              'attention_dropout_prob': 0.1,\n",
       "              'hidden_dropout_prob': 0.1,\n",
       "              'hidden_size': 768,\n",
       "              'num_attention_heads': 12,\n",
       "              'num_hidden_layers': 12,\n",
       "              'intermediate_size': 3072,\n",
       "              'layer_norm_eps': 1e-05,\n",
       "              'max_position_embeddings': 512,\n",
       "              'vocab_size': 21128,\n",
       "              'type_vocab_size': 2,\n",
       "              '__dict__': <attribute '__dict__' of 'ChineseBERTBaseConfig' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'ChineseBERTBaseConfig' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model config\n",
    "vars(ChineseBERTBaseConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CachedBertEncoder(ChineseBERTBaseConfig)\n",
    "decoder = CachedBertDecoderLM(ChineseBERTBaseConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can either download or train your own adaption model\n",
    "model_states = torch.load(\"../models/adapt.pth\")\n",
    "\n",
    "encoder.load_state_dict(model_states['encoder'], strict=False)\n",
    "decoder.load_state_dict(model_states['decoder'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send to cuda\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper-parameters\n",
    "num_epochs = 10\n",
    "num_gradients_accumulation = 1\n",
    "num_train_optimization_steps = len(train_dataset) * num_epochs // batch_size // num_gradients_accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not decay bias\n",
    "param_optimizer = list(encoder.named_parameters()) + list(decoder.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.01\n",
    "    }, {\n",
    "        'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "# setup optimizier\n",
    "optimizer = FusedAdam(optimizer_grouped_parameters, \n",
    "                      lr=1e-5, \n",
    "                      eps=1e-06,\n",
    "                      bias_correction=False)\n",
    "\n",
    "scheduler = WarmupLinearSchedule(\n",
    "    optimizer, warmup_steps=int(num_train_optimization_steps * 0.1), t_total=num_train_optimization_steps\n",
    ")\n",
    "\n",
    "# enable fp16\n",
    "[encoder, decoder], optimizer = amp.initialize([encoder, decoder], optimizer, opt_level='O1')\n",
    "\n",
    "# set up loss\n",
    "criterion = SequenceFocalLoss(gamma=a, beta=b)\n",
    "eval_criterion = SequenceCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = SimpleCheckpointer(model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4600 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/4600 [00:00<?, ?it/s, loss=3.49, perplexity=32.7, speed=34.3]\u001b[A\n",
      "\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3/300 [00:00<00:10, 28.88it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|▏         | 6/300 [00:00<00:10, 28.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10/300 [00:00<00:09, 29.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 14/300 [00:00<00:09, 30.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 17/300 [00:00<00:09, 30.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 21/300 [00:00<00:09, 30.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 25/300 [00:00<00:09, 30.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 29/300 [00:00<00:08, 30.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 32/300 [00:01<00:08, 30.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 36/300 [00:01<00:08, 30.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 39/300 [00:01<00:08, 29.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 42/300 [00:01<00:08, 29.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 46/300 [00:01<00:08, 30.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 50/300 [00:01<00:08, 30.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 54/300 [00:01<00:07, 30.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 58/300 [00:01<00:07, 30.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 62/300 [00:02<00:07, 30.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 66/300 [00:02<00:07, 30.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 70/300 [00:02<00:07, 30.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 74/300 [00:02<00:07, 29.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 77/300 [00:02<00:07, 29.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 80/300 [00:02<00:07, 29.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 83/300 [00:02<00:07, 28.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 87/300 [00:03<00:10, 20.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 91/300 [00:03<00:09, 23.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 95/300 [00:03<00:08, 25.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 98/300 [00:03<00:07, 26.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 102/300 [00:03<00:07, 27.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 106/300 [00:03<00:06, 28.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 109/300 [00:03<00:06, 29.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 112/300 [00:03<00:06, 29.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 116/300 [00:04<00:06, 29.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 120/300 [00:04<00:06, 29.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 124/300 [00:04<00:05, 30.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 128/300 [00:04<00:05, 29.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 131/300 [00:04<00:05, 29.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 135/300 [00:04<00:05, 29.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 139/300 [00:04<00:05, 30.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 143/300 [00:04<00:05, 30.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 147/300 [00:05<00:04, 31.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 151/300 [00:05<00:04, 31.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 155/300 [00:05<00:04, 31.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 159/300 [00:05<00:04, 31.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 163/300 [00:05<00:04, 31.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 167/300 [00:05<00:04, 31.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 171/300 [00:05<00:04, 31.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 175/300 [00:05<00:03, 31.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 179/300 [00:06<00:03, 31.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 183/300 [00:06<00:03, 31.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 187/300 [00:06<00:03, 31.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 191/300 [00:06<00:03, 31.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 195/300 [00:06<00:03, 31.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 199/300 [00:06<00:03, 31.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 203/300 [00:06<00:03, 31.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 207/300 [00:06<00:02, 31.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 211/300 [00:07<00:02, 31.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 215/300 [00:07<00:02, 31.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 219/300 [00:07<00:02, 31.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 223/300 [00:07<00:02, 31.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 227/300 [00:07<00:02, 31.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 231/300 [00:07<00:02, 31.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 235/300 [00:07<00:02, 31.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 239/300 [00:07<00:01, 31.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 243/300 [00:08<00:01, 31.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 247/300 [00:08<00:01, 31.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 251/300 [00:08<00:01, 31.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 255/300 [00:08<00:01, 31.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 259/300 [00:08<00:01, 31.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 263/300 [00:08<00:01, 31.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 267/300 [00:08<00:01, 31.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 271/300 [00:08<00:00, 31.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 275/300 [00:09<00:00, 31.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 279/300 [00:09<00:00, 30.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 283/300 [00:09<00:00, 30.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 287/300 [00:09<00:00, 30.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 291/300 [00:09<00:00, 30.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 295/300 [00:09<00:00, 30.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 300/300 [00:09<00:00, 30.25it/s]\u001b[A\u001b[A\n",
      "2020-02-04 00:40:18,649 - __main__ - INFO - a=0.5 b=20.0 Epoch 0 Validation perplexity: 28.58344626188278\n",
      "\n",
      "\n",
      "  0%|          | 0/4600 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/4600 [00:00<?, ?it/s, loss=3.97, perplexity=52.8, speed=0.475]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 3/300 [00:00<00:10, 28.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 7/300 [00:00<00:09, 29.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▎         | 11/300 [00:00<00:09, 30.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▍         | 14/300 [00:00<00:09, 30.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▌         | 18/300 [00:00<00:09, 30.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 22/300 [00:00<00:09, 30.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▊         | 26/300 [00:00<00:08, 30.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 30/300 [00:00<00:08, 31.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|█▏        | 34/300 [00:01<00:08, 31.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█▎        | 38/300 [00:01<00:08, 31.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▍        | 42/300 [00:01<00:08, 31.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▌        | 46/300 [00:01<00:08, 31.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 50/300 [00:01<00:07, 31.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 54/300 [00:01<00:07, 31.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|█▉        | 58/300 [00:01<00:07, 31.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|██        | 62/300 [00:01<00:07, 31.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 66/300 [00:02<00:07, 31.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 70/300 [00:02<00:07, 31.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▍       | 74/300 [00:02<00:07, 31.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██▌       | 78/300 [00:02<00:07, 31.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██▋       | 82/300 [00:02<00:06, 31.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|██▊       | 86/300 [00:02<00:06, 31.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███       | 90/300 [00:02<00:06, 31.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███▏      | 94/300 [00:03<00:06, 30.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 98/300 [00:03<00:06, 30.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|███▍      | 102/300 [00:03<00:06, 30.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|███▌      | 106/300 [00:03<00:06, 30.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|███▋      | 110/300 [00:03<00:06, 30.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███▊      | 114/300 [00:03<00:06, 30.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|███▉      | 118/300 [00:03<00:05, 30.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████      | 122/300 [00:03<00:05, 30.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████▏     | 126/300 [00:04<00:05, 31.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████▎     | 130/300 [00:04<00:05, 29.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|████▍     | 134/300 [00:04<00:05, 30.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|████▌     | 138/300 [00:04<00:05, 30.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|████▋     | 142/300 [00:04<00:05, 30.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|████▊     | 146/300 [00:04<00:04, 30.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 150/300 [00:04<00:04, 30.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████▏    | 154/300 [00:04<00:04, 30.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████▎    | 158/300 [00:05<00:04, 30.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████▍    | 162/300 [00:05<00:04, 31.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████▌    | 166/300 [00:05<00:04, 31.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▋    | 170/300 [00:05<00:04, 31.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|█████▊    | 174/300 [00:05<00:04, 31.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|█████▉    | 178/300 [00:05<00:03, 31.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|██████    | 182/300 [00:05<00:03, 31.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████▏   | 186/300 [00:05<00:03, 31.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████▎   | 190/300 [00:06<00:03, 31.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|██████▍   | 194/300 [00:06<00:03, 31.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████▌   | 198/300 [00:06<00:03, 31.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 202/300 [00:06<00:03, 31.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████▊   | 206/300 [00:06<00:03, 31.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|███████   | 210/300 [00:06<00:02, 31.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████▏  | 214/300 [00:06<00:02, 31.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████▎  | 218/300 [00:07<00:02, 31.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|███████▍  | 222/300 [00:07<00:02, 31.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 226/300 [00:07<00:02, 30.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|███████▋  | 230/300 [00:07<00:02, 31.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 234/300 [00:07<00:02, 31.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|███████▉  | 238/300 [00:07<00:02, 30.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|████████  | 242/300 [00:07<00:01, 30.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████▏ | 246/300 [00:07<00:01, 31.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████▎ | 250/300 [00:08<00:01, 31.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████▍ | 254/300 [00:08<00:01, 32.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████▌ | 258/300 [00:08<00:01, 32.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|████████▋ | 262/300 [00:08<00:01, 32.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|████████▊ | 266/300 [00:08<00:01, 31.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|█████████ | 270/300 [00:08<00:00, 31.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|█████████▏| 274/300 [00:08<00:00, 31.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|█████████▎| 278/300 [00:08<00:00, 31.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|█████████▍| 282/300 [00:09<00:00, 31.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|█████████▌| 286/300 [00:09<00:00, 32.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████▋| 290/300 [00:09<00:00, 31.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████▊| 294/300 [00:09<00:00, 32.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 300/300 [00:09<00:00, 31.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "2020-02-04 00:40:28,846 - __main__ - INFO - a=0.5 b=20.0 Epoch 1 Validation perplexity: 28.741768460591633\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4600 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/4600 [00:00<?, ?it/s, loss=3.23, perplexity=25.3, speed=0.49]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 3/300 [00:00<00:10, 28.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 7/300 [00:00<00:10, 29.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|▎         | 11/300 [00:00<00:09, 30.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 15/300 [00:00<00:09, 30.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|▋         | 19/300 [00:00<00:09, 31.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 23/300 [00:00<00:08, 31.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 27/300 [00:00<00:08, 31.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 31/300 [00:00<00:08, 32.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 35/300 [00:01<00:08, 32.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 39/300 [00:01<00:08, 32.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 43/300 [00:01<00:07, 32.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 47/300 [00:01<00:07, 32.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 51/300 [00:01<00:07, 31.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 55/300 [00:01<00:07, 32.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|█▉        | 59/300 [00:01<00:07, 31.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|██        | 63/300 [00:01<00:07, 31.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 67/300 [00:02<00:07, 31.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▎       | 71/300 [00:02<00:07, 32.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 75/300 [00:02<00:06, 32.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 79/300 [00:02<00:06, 31.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 83/300 [00:02<00:07, 30.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 87/300 [00:02<00:06, 30.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 91/300 [00:02<00:06, 31.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 95/300 [00:02<00:06, 31.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 99/300 [00:03<00:06, 32.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 103/300 [00:03<00:06, 32.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 107/300 [00:03<00:05, 32.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 111/300 [00:03<00:05, 32.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 115/300 [00:03<00:05, 32.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███▉      | 119/300 [00:03<00:05, 32.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|████      | 123/300 [00:03<00:05, 32.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 127/300 [00:03<00:05, 32.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████▎     | 131/300 [00:04<00:05, 30.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 135/300 [00:04<00:05, 29.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▋     | 139/300 [00:04<00:05, 30.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 143/300 [00:04<00:05, 31.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 147/300 [00:04<00:04, 31.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 151/300 [00:04<00:04, 31.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 155/300 [00:04<00:04, 32.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 159/300 [00:05<00:04, 31.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 163/300 [00:05<00:04, 30.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████▌    | 167/300 [00:05<00:04, 30.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 171/300 [00:05<00:04, 30.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 175/300 [00:05<00:04, 30.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████▉    | 179/300 [00:05<00:03, 31.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████    | 183/300 [00:05<00:03, 30.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 187/300 [00:05<00:03, 30.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████▎   | 191/300 [00:06<00:03, 30.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 195/300 [00:06<00:03, 31.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████▋   | 199/300 [00:06<00:03, 32.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 203/300 [00:06<00:03, 32.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▉   | 207/300 [00:06<00:02, 32.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 211/300 [00:06<00:02, 31.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 215/300 [00:06<00:02, 31.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 219/300 [00:06<00:02, 32.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 223/300 [00:07<00:02, 32.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████▌  | 227/300 [00:07<00:02, 31.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 231/300 [00:07<00:02, 31.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 235/300 [00:07<00:02, 31.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████▉  | 239/300 [00:07<00:01, 31.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 243/300 [00:07<00:01, 31.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 247/300 [00:07<00:01, 31.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▎ | 251/300 [00:07<00:01, 31.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 255/300 [00:08<00:01, 31.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▋ | 259/300 [00:08<00:01, 30.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 263/300 [00:08<00:01, 30.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████▉ | 267/300 [00:08<00:01, 29.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 271/300 [00:08<00:00, 30.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 275/300 [00:08<00:00, 30.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 279/300 [00:08<00:00, 29.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|█████████▍| 283/300 [00:08<00:00, 30.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 287/300 [00:09<00:00, 29.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 291/300 [00:09<00:00, 30.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 295/300 [00:09<00:00, 30.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 300/300 [00:09<00:00, 31.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "2020-02-04 00:40:39,011 - __main__ - INFO - a=0.5 b=20.0 Epoch 2 Validation perplexity: 28.798720911502837\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4600 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4600 [00:00<?, ?it/s, loss=3.67, perplexity=39.3, speed=0.493]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 3/300 [00:00<00:10, 28.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 7/300 [00:00<00:09, 29.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▎         | 11/300 [00:00<00:09, 30.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 15/300 [00:00<00:09, 31.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▋         | 19/300 [00:00<00:08, 31.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 23/300 [00:00<00:08, 31.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▊         | 26/300 [00:00<00:08, 31.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|▉         | 29/300 [00:00<00:08, 30.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|█         | 33/300 [00:01<00:08, 30.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 37/300 [00:01<00:08, 30.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▎        | 41/300 [00:01<00:08, 30.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 45/300 [00:01<00:08, 30.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▋        | 49/300 [00:01<00:08, 30.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 53/300 [00:01<00:08, 30.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 57/300 [00:01<00:07, 30.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 61/300 [00:01<00:07, 30.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 65/300 [00:02<00:07, 30.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 69/300 [00:02<00:07, 30.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 73/300 [00:02<00:07, 31.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 77/300 [00:02<00:07, 31.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 81/300 [00:02<00:07, 30.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 85/300 [00:02<00:06, 30.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|██▉       | 89/300 [00:02<00:06, 31.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███       | 93/300 [00:02<00:06, 31.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 97/300 [00:03<00:06, 31.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▎      | 101/300 [00:03<00:06, 31.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 105/300 [00:03<00:06, 31.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▋      | 109/300 [00:03<00:05, 32.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2c7940cba920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     checkpointer.save_checkpoint(\n\u001b[1;32m     33\u001b[0m         str(ep), {\n",
      "\u001b[0;32m<ipython-input-7-458c13560996>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/TorchFly/torchfly/modules/transformers/cached_bert_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, mask, past, position_ids)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlm_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/TorchFly/torchfly/modules/transformers/cached_bert_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past, mask, token_type_ids, position_ids)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# Transformer layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mlast_layer_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlast_layer_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/TorchFly/torchfly/modules/transformers/cached_bert_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, past)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_past\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mpresents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/TorchFly/torchfly/modules/transformers/cached_bert_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, mask)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/TorchFly/torchfly/modules/transformers/cached_bert_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, layer_past, mask)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/TorchFly/torchfly/modules/transformers/cached_bert_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, mask)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mmixed_key_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/wrap.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m                                      \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                      kwargs)\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0morig_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/apex/amp/wrap.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m                                      \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                      kwargs)\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0morig_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "update_count = 0\n",
    "start = time.time()\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "    \"Training\"\n",
    "    pb = tqdm.tqdm(train_dataloader)\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    for batch in pb:\n",
    "        record_loss, perplexity = train_one_iter(batch, fp16=True)\n",
    "        update_count += 1\n",
    "\n",
    "        if update_count % num_gradients_accumulation == num_gradients_accumulation - 1:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # speed measure\n",
    "            end = time.time()\n",
    "            speed = batch_size * num_gradients_accumulation / (end - start)\n",
    "            start = end\n",
    "\n",
    "            pb.set_postfix(loss=record_loss, perplexity=perplexity, speed=speed)\n",
    "            \n",
    "    \"Evaluation\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    ppl = validate(val_dataloader)\n",
    "    checkpointer.save_checkpoint(\n",
    "        str(ep), {\n",
    "            \"encoder\": encoder.state_dict(),\n",
    "            \"decoder\": decoder.state_dict()\n",
    "        }, {\"empty\": None}\n",
    "    )\n",
    "\n",
    "    logger.info(f\"a={a} b={b} Epoch {ep} Validation perplexity: {ppl}\")\n",
    "\n",
    "logger.info(f\"Finish training of alpha={a} beta={b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
